{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PokedexTransferLearning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPNCDHZf5HiO579MkGQY21n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itleBhJOnjAO",
        "colab_type": "text"
      },
      "source": [
        "This is transfer learning CNN codes; VGG16 is used for transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxSsjNvZfgRd",
        "colab_type": "text"
      },
      "source": [
        "Mount GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDJvulw2ntgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01c0cDJ-n1kp",
        "colab_type": "text"
      },
      "source": [
        "Install the necessary packages or libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ztJrfONpVvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import keras\n",
        "import os\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "import matplotlib as mlp\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyq_ZCdDhpWZ",
        "colab_type": "text"
      },
      "source": [
        "load VGG16 structure (delete fully connected layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvrN2EzFhr_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9aVe-dZPOzh",
        "colab_type": "text"
      },
      "source": [
        "Define Path, folder and dirname in this step, to be used later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCGdQcJcPWDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define path, folder and dirname(pokemon name folder)\n",
        "path = '/content/gdrive/My Drive/dlpokedex/dataset'\n",
        "print(path) # optional, show the path as printed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWN7n5adiu9M",
        "colab_type": "text"
      },
      "source": [
        "define a method to load and preprocess the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMrtdYRji06a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelProcess(img_path, model):\n",
        "    img = load_img(img_path, target_size=(224, 224)) # read image path, resize to 224,224, required by VGG16\n",
        "    img = img_to_array(img) # transfer to Image Array\n",
        "    x = np.expand_dims(img, axis=0) # add one dimention to load into VGG\n",
        "    x = preprocess_input(x) # preprocessing\n",
        "    x_vgg = model.predict(x) #otbain features，the shape before Fully Connected layer\n",
        "\n",
        "    x_vgg = x_vgg.reshape(1, 25088) # Connect to FC layer\n",
        "    return x_vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UQpPQnnkPmc",
        "colab_type": "text"
      },
      "source": [
        "list file names of the training datasets: Path=...dlpokedex; folders=pokemon folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ4g_mWHkSW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list file names of the training datasets\n",
        "def transform_format(path):  # transform format\n",
        "    folders = os.listdir(path)  # read pokemon labels(folders), so we only need specify path in the codes\n",
        "    for j in range(len(folders)):\n",
        "        dirName = path + '//' + folders[j] + '//'  # folders have name of pokemon\n",
        "        li = os.listdir(dirName)  # all pokemon images are named after its folder name, dirname=path/folder\n",
        "        for filename in li:\n",
        "            newname = filename\n",
        "            newname = newname.split(\".\")  # filename is each pokemon picture and divided by \".\"\n",
        "            if newname[-1] != \"png\":  # reformate all images to png format\n",
        "                newname[-1] = \"png\"\n",
        "                newname = str.join(\".\", newname)  # use str.join here\n",
        "                filename = dirName + filename\n",
        "                newname = dirName + newname\n",
        "                os.rename(filename, newname)  # rename to newname\n",
        "                print('reading the images:%s' % (newname))  # optional step to see if there is bugs in reading images\n",
        "                a = np.array(Image.open(newname))  # read image array\n",
        "                if ((len(a.shape) != 3) or (a.shape[2] != 3)):  # check if all images are in RGB format\n",
        "                    a = np.array(Image.open(newname).convert('RGB'))  # change to RGB\n",
        "                    img = Image.fromarray(a.astype('uint8'))  # form image\n",
        "                    img.save(newname)  # replace old image\n",
        "                    print(a.shape)  # test print\n",
        "    print(\"all images transfered to PNG file\")\n",
        "    print(\"all images transfered to RGB format\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8_dA3pxlK_w",
        "colab_type": "text"
      },
      "source": [
        "Start processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnLqOzQ9nMhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(path):\n",
        "    folders = os.listdir(path) # read image folders, for example 5 folders if 5 pockemon\n",
        "    for j in range(len(folders)): # cycle # = folder #\n",
        "        folder = path + '//' + folders[j] # folders, or pockemon labels\n",
        "        dirs = os.listdir(folder) # read all images under each folder\n",
        "        # path for image\n",
        "        img_path = []\n",
        "        for i in dirs:\n",
        "            if os.path.splitext(i)[1] == \".png\": # has done transformation into png image\n",
        "                img_path.append(i)\n",
        "        img_path = [folder + \"//\" + i for i in img_path] \n",
        "        # full path of each image\n",
        "        \n",
        "        # start processing\n",
        "        features1 = np.zeros([len(img_path), 25088]) # array each image\n",
        "        for i in range(len(img_path)):\n",
        "            feature_i = modelProcess(img_path[i], model_vgg) # process image by image\n",
        "            print('preprocessed:', img_path[i])\n",
        "            features1[i] = feature_i\n",
        "        if j == 0: # add all images array together\n",
        "            X = features1 # first cycle\n",
        "        else:\n",
        "            X = np.concatenate((X, features1), axis=0)\n",
        "            # concatenate image after image\n",
        "    return X # all images are concatenated together at last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf-ajc5RsBN5",
        "colab_type": "text"
      },
      "source": [
        "read the images data and label images with 5 pokemon names(folder name), takes long time to process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjZevX4OsVu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/gdrive/My Drive/dlpokedex/dataset' # Path to dataset\n",
        "# one-hot encoding\n",
        "y = []\n",
        "folders = os.listdir(path)  # load path of dataset\n",
        "for j in range(len(folders)): # j: 0, 1, 2, 3, 4 ; \n",
        "    dirName = path + '//' + folders[j] + '//'  # folder path\n",
        "    lens = len(os.listdir(dirName)) # number of images under each Pokemon label (folder)\n",
        "    for i in range(lens):\n",
        "        y.append(j) # append images\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y) # one-hot encoding\n",
        "\n",
        "transform_format(path)  # format transformation\n",
        "X = read_data(path) # read data\n",
        "print('X.shape:', X.shape)\n",
        "print('y.shape:', y.shape)\n",
        "print('-' * 35)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RiQPAWizzgd",
        "colab_type": "text"
      },
      "source": [
        "## Above output(now shown) show the processing of transfer images to png file, in RGB format, resize to (244x244), label of images, i.e. the process defined in previous steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aShLOI6Az0Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# partition train and test(validation) data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
        "print('X_train.shape:', X_train.shape)\n",
        "print('X_test.shape:', X_test.shape)\n",
        "print('y_train.shape:', y_train.shape)\n",
        "print('y_test.shape:', y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNaZQilxVuWO",
        "colab_type": "text"
      },
      "source": [
        "Start model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lbHFMXXVzJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=40, activation='relu', input_dim=25088))\n",
        "\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "# if label of Pokemon =5 ，then units=5，multicategory we use softmax，if binary we use sigmoid\n",
        "model.summary()\n",
        "# check model structure\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvR0NLTjZdeP",
        "colab_type": "text"
      },
      "source": [
        "model started successfully "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOhoUASHWTsu",
        "colab_type": "text"
      },
      "source": [
        "Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qZO3hqlWVtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configure the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# optimizer Adam，define loss function，here we use categorical_crossentropy，Metrics is accuracy\n",
        "# train the model, modified for both train and test(validation), add batch size, \n",
        "hist=model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1,\n",
        "               validation_data =(X_test, y_test))\n",
        "# start training，epochs=20\n",
        "# define variables for accuracy and loss ploting\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['accuracy']\n",
        "val_acc=hist.history['val_accuracy']\n",
        "xc=range(20) # 20 is the epochs number, modify if epochs number change"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v33ES91OPH93",
        "colab_type": "text"
      },
      "source": [
        "Now we see the history of epochs for both train and validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY1zjTzcZl0T",
        "colab_type": "text"
      },
      "source": [
        "Run model for 20 epochs successfully :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AHAvFBLaEUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summary the model\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPxQhmjWbW7",
        "colab_type": "text"
      },
      "source": [
        "Plot accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTJaIrDDQIAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(1, figsize=(7, 5))\n",
        "plt.plot(xc, train_loss)\n",
        "plt.plot(xc, val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train', 'val'])\n",
        "# print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "plt.savefig('trial_psi_loss.png', bbox_inches='tight')\n",
        "\n",
        "plt.figure(2, figsize=(7, 5))\n",
        "plt.plot(xc, train_acc)\n",
        "plt.plot(xc, val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train', 'val'], loc=4)\n",
        "# print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "plt.savefig('trial_psi_acc.png', bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1AFJ0qgPU8W",
        "colab_type": "text"
      },
      "source": [
        "Plot the Confusion Matrix for validation data(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppqYW-FjWj3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train dataset decoding, optional\n",
        "y_train_predict = model.predict_classes(X_train)  \n",
        "y_trainnew = lb.inverse_transform(y_train)\n",
        "# decoding from one-hot encoding\n",
        "\n",
        "\n",
        "# valication(test) accuracy, y_test_predict and y_testnew will be used to plot confusion matrix\n",
        "y_test_predict = model.predict_classes(X_test) \n",
        "y_testnew = lb.inverse_transform(y_test)\n",
        "# decoding from one-hot encoding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiZ3IzXEyeq9",
        "colab_type": "text"
      },
      "source": [
        "Define confusion matrix (cm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFrhDrA6kBtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries and define cm(confusion matrix)\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = metrics.confusion_matrix(y_testnew, y_test_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODiJswBkGY1",
        "colab_type": "text"
      },
      "source": [
        "Define a function to plot the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3OB_Hl3kH1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining function for confusion matrix plot\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Computing confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "# Visualizing\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "   # Rotating the tick labels and setting their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    # Looping over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmy102ickase",
        "colab_type": "text"
      },
      "source": [
        "Specify a Pokemon index to display in confusion matrix, i.e. class_names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z4881UEkxSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names= folders\n",
        "# folders are the index of Pokemon folders defined in earlier steps of the model building"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1E3NPbjk38L",
        "colab_type": "text"
      },
      "source": [
        "Plot non-nomalized cm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lNsaLZvk7Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Non-Normalized Confusion Matrix\n",
        "plt.figure(figsize=(20,20))\n",
        "plot_confusion_matrix(y_testnew, y_test_predict, classes = class_names, title='Non-Normalized Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZJFqpEdk-TP",
        "colab_type": "text"
      },
      "source": [
        "Plot normalized cm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5dvek9elJIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalized Confusion Matrix\n",
        "plt.figure(figsize=(35,35))\n",
        "plot_confusion_matrix(y_testnew, y_test_predict, classes = class_names, normalize=True, title='Non-Normalized Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3y4CibwlXtY",
        "colab_type": "text"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT8---dZlZFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/gdrive/My Drive/dlpokedex/Pokedex_modelTL.h5')  # save your model with h5py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}